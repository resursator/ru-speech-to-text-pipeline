Directory structure:
└── agat-test/
    ├── asr_service.py
    ├── config.py
    ├── docker-compose.yml
    ├── Dockerfile
    ├── Dockerfile.asr
    ├── main.py
    ├── redis_client.py
    ├── requirements.txt
    ├── schemas.py
    └── worker.py

================================================
FILE: asr_service.py
================================================
"""
ASR-сервис на базе официального пакета qwen-asr.
Принимает WAV (16кГц, моно), делит на 30-секундные сегменты,
возвращает список сегментов с временными метками.
"""

import os
import tempfile
import torch
import torchaudio
from typing import List, Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, HTTPException
from pydantic import BaseModel

from qwen_asr import Qwen3ASRModel

# ---------------------------------------------------------------------------
# Конфигурация
# ---------------------------------------------------------------------------
MODEL_ID      = os.getenv("ASR_MODEL_ID",       "Qwen/Qwen3-ASR-1.7B")
LANGUAGE      = os.getenv("ASR_LANGUAGE",        "Russian")   # None = авто-определение
CHUNK_LENGTH_S = int(os.getenv("ASR_CHUNK_S",   "30"))
MAX_NEW_TOKENS = int(os.getenv("ASR_MAX_TOKENS", "256"))
SILENCE_THRESH = float(os.getenv("ASR_SILENCE",  "0.01"))
DEVICE         = "cuda" if torch.cuda.is_available() else "cpu"

# ---------------------------------------------------------------------------
# Модель — загружается один раз при старте
# ---------------------------------------------------------------------------
_model: Optional[Qwen3ASRModel] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    global _model
    print(f"[ASR] Loading {MODEL_ID} on {DEVICE}...")
    _model = Qwen3ASRModel.from_pretrained(
        MODEL_ID,
        dtype=torch.bfloat16 if DEVICE == "cuda" else torch.float32,
        device_map=DEVICE,
        max_inference_batch_size=8,
        max_new_tokens=MAX_NEW_TOKENS,
    )
    print("[ASR] Model ready.")
    yield


app = FastAPI(title="Qwen3-ASR Service", lifespan=lifespan)


# ---------------------------------------------------------------------------
# Схемы ответа
# ---------------------------------------------------------------------------
class Segment(BaseModel):
    start: float
    end:   float
    text:  str


class TranscribeResponse(BaseModel):
    task_id:     Optional[str]
    language:    Optional[str]
    full_text:   str
    segments:    List[Segment]


# ---------------------------------------------------------------------------
# Эндпоинт
# ---------------------------------------------------------------------------
@app.post("/transcribe", response_model=TranscribeResponse)
async def transcribe(
    file:    UploadFile = File(...),
    task_id: str        = "",
):
    """
    Принимает WAV-файл (16кГц, моно).
    Нарезает на CHUNK_LENGTH_S-секундные куски, транскрибирует каждый
    через qwen-asr, возвращает сегменты + склеенный полный текст.
    """
    # --- сохраняем загруженный файл во временный WAV ---
    suffix = os.path.splitext(file.filename or "audio.wav")[1] or ".wav"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name

    try:
        # --- загружаем аудио ---
        waveform, sr = torchaudio.load(tmp_path)

        # приводим к моно
        if waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)

        # ресемплируем до 16 кГц
        if sr != 16000:
            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)
            sr = 16000

        total_samples  = waveform.shape[1]
        chunk_samples  = CHUNK_LENGTH_S * sr
        segments: List[Segment] = []
        detected_lang: Optional[str] = None

        # --- обрабатываем по сегментам ---
        for start in range(0, total_samples, chunk_samples):
            end   = min(start + chunk_samples, total_samples)
            chunk = waveform[:, start:end]   # (1, N)

            # пропускаем тишину
            if torch.max(torch.abs(chunk)).item() < SILENCE_THRESH:
                continue

            audio_np = chunk.squeeze().numpy()   # (N,)

            # qwen-asr принимает (np.ndarray, sr) tuple напрямую
            results = _model.transcribe(
                audio=(audio_np, sr),
                language=LANGUAGE if LANGUAGE != "auto" else None,
            )

            res = results[0]
            text = (res.text or "").strip()

            if detected_lang is None:
                detected_lang = getattr(res, "language", None)

            if text:
                segments.append(Segment(
                    start=start / sr,
                    end=end   / sr,
                    text=text,
                ))

        full_text = " ".join(s.text for s in segments)

        return TranscribeResponse(
            task_id=task_id or None,
            language=detected_lang,
            full_text=full_text,
            segments=segments,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

    finally:
        os.unlink(tmp_path)


@app.get("/health")
async def health():
    return {"status": "ok", "model": MODEL_ID, "device": DEVICE}



================================================
FILE: config.py
================================================
import os

REDIS_HOST = os.getenv("REDIS_HOST", "redis")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_QUEUE = os.getenv("REDIS_QUEUE", "audio_tasks")

UPLOAD_DIR = os.getenv("UPLOAD_DIR", "./uploads")



================================================
FILE: docker-compose.yml
================================================
services:
  # -----------------------------------------------------------------------
  # API — приём файлов, постановка задач в очередь
  # -----------------------------------------------------------------------
  api:
    build:
      context: .
      dockerfile: Dockerfile
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    depends_on:
      - redis
    environment:
      - REDIS_HOST=redis
    volumes:
      - ./examples/uploads:/app/uploads
      - ./main.py:/app/main.py

  # -----------------------------------------------------------------------
  # Worker — конвертация (ffmpeg) + шумоподавление (CPU)
  # НЕТ GPU, НЕТ тяжёлых ML-зависимостей
  # -----------------------------------------------------------------------
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    command: celery -A worker worker --loglevel=info --concurrency=2
    depends_on:
      - redis
      - asr
    environment:
      - REDIS_HOST=redis
      - ASR_SERVICE_URL=http://asr:8001
    volumes:
      - ./examples/uploads:/app/uploads
      - ./worker.py:/app/worker.py

  # -----------------------------------------------------------------------
  # ASR — GPU-контейнер с Qwen3-ASR
  # -----------------------------------------------------------------------
  asr:
    build:
      context: .
      dockerfile: Dockerfile.asr
    # ports:
    #   - "8001:8001"
    environment:
      - ASR_MODEL_ID=Qwen/Qwen3-ASR-1.7B
      - ASR_LANGUAGE=Russian # или "auto" для авто-определения
      - ASR_CHUNK_S=30
      - ASR_MAX_TOKENS=256
    volumes:
      - ./asr_service.py:/app/asr_service.py
      - qwen-models:/root/.cache/huggingface
    devices:
      - nvidia.com/gpu=all

  # -----------------------------------------------------------------------
  # Redis
  # -----------------------------------------------------------------------
  redis:
    image: redis:8.0-alpine
    ports:
      - "6379:6379"

# -----------------------------------------------------------------------
# Volumes
# -----------------------------------------------------------------------
volumes:
  qwen-models:
    driver: local
    driver_opts:
      type: "none"
      o: "bind"
      device: "/home/resursator/.cache/huggingface/"



================================================
FILE: Dockerfile
================================================
FROM python:3.11-slim

WORKDIR /app
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY *.py .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]



================================================
FILE: Dockerfile.asr
================================================
# CUDA-образ для ASR-сервиса (Qwen3-ASR через официальный пакет qwen-asr)
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

RUN apt-get update && apt-get install -y \
    python3.11 python3.11-dev python3-pip \
    ffmpeg libsndfile1 git \
    && ln -sf /usr/bin/python3.11 /usr/bin/python3 \
    && ln -sf /usr/bin/python3    /usr/bin/python \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Torch с поддержкой CUDA 12.1
RUN pip install --upgrade pip && \
    pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# Официальный пакет qwen-asr (включает transformers-бэкенд)
RUN pip install qwen-asr

# FastAPI / Uvicorn
RUN pip install fastapi uvicorn[standard] python-multipart

COPY asr_service.py .

CMD ["uvicorn", "asr_service:app", "--host", "0.0.0.0", "--port", "8001"]



================================================
FILE: main.py
================================================
import uuid
import json
import os
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, HTTPException

from redis_client import redis_client
from config import REDIS_QUEUE, UPLOAD_DIR
from schemas import AudioTask
from worker import process_audio

app = FastAPI(title="Audio Ingest API")

os.makedirs(UPLOAD_DIR, exist_ok=True)


@app.post("/upload")
async def upload_audio(
    file: UploadFile = File(...),
    callback_url: str = "None"
):
    if not file.filename:
        raise HTTPException(status_code=400, detail="Empty filename")

    task_id = str(uuid.uuid4())
    save_path = os.path.join(UPLOAD_DIR, f"{task_id}_{file.filename}")

    # save file
    with open(save_path, "wb") as f:
        content = await file.read()
        f.write(content)

    # task = AudioTask(
    #     task_id=task_id,
    #     filename=file.filename,
    #     path=save_path,
    #     created_at=datetime.utcnow().isoformat(),
    #     callback_url=callback_url
    # )

    # push to redis queue
    # redis_client.rpush(REDIS_QUEUE, json.dumps(task.model_dump()))
    process_audio.delay(task_id, save_path, callback_url)

    return {
        "task_id": task_id,
        "status": "queued"
    }



================================================
FILE: redis_client.py
================================================
import redis
from config import REDIS_HOST, REDIS_PORT

redis_client = redis.Redis(
    host=REDIS_HOST,
    port=REDIS_PORT,
    decode_responses=True
)



================================================
FILE: requirements.txt
================================================
celery==5.6.2
fastapi==0.121.1
noisereduce==3.0.3
numpy==2.3.5
pydantic==2.12.4
pydantic_core==2.41.5
python-multipart==0.0.20
redis==6.2.0
requests==2.32.5
soundfile==0.13.1
uvicorn==0.38.0



================================================
FILE: schemas.py
================================================
from pydantic import BaseModel
from datetime import datetime

class AudioTask(BaseModel):
    task_id: str
    filename: str
    path: str
    created_at: str
    status: str = "uploaded"
    callback_url: str = "None"



================================================
FILE: worker.py
================================================
import os
import subprocess
import json
import requests
from celery import Celery, chain
from celery.exceptions import TaskError
import time
from typing import Dict, Any, Optional
import noisereduce
import soundfile

from config import REDIS_HOST, REDIS_PORT, UPLOAD_DIR
from redis_client import redis_client

# ---------------------------------------------------------------------------
# ASR-сервис
# ---------------------------------------------------------------------------
ASR_SERVICE_URL = os.getenv("ASR_SERVICE_URL", "http://asr:8001")

# ---------------------------------------------------------------------------
# Celery
# ---------------------------------------------------------------------------
celery_app = Celery(
    'audio_worker',
    broker=f'redis://{REDIS_HOST}:{REDIS_PORT}/0',
    backend=f'redis://{REDIS_HOST}:{REDIS_PORT}/0',
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=30 * 60,
    task_soft_time_limit=25 * 60,
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    task_default_retry_delay=5,
    task_max_retries=3,
    task_always_eager=False,
)

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def update_task_status(task_id: str, status: str, result: Optional[Dict[str, Any]] = None):
    try:
        task_key  = f"task:{task_id}"
        task_data = {"status": status, "updated_at": str(time.time())}
        if result:
            task_data["result"] = json.dumps(result)
        redis_client.hset(task_key, mapping=task_data)
        redis_client.expire(task_key, 3600)
    except Exception as e:
        print(f"Error updating status for task {task_id}: {e}")


def send_callback(callback_url: str, task_id: str, status: str, result: Optional[Dict[str, Any]] = None):
    if callback_url and callback_url != "None":
        try:
            requests.post(
                callback_url,
                json={"task_id": task_id, "status": status, "result": result or {}},
                timeout=5,
            )
        except Exception as e:
            print(f"Callback failed for task {task_id}: {e}")


# ---------------------------------------------------------------------------
# Tasks
# ---------------------------------------------------------------------------

@celery_app.task(bind=True, name='convert')
def ffmpeg_convert(self, task_id: str, input_path: str, output_format: str = 'wav', callback_url: str = "None"):
    """Конвертирует аудио в WAV 16кГц моно через ffmpeg."""
    update_task_status(task_id, "converting")
    try:
        base_name   = os.path.splitext(input_path)[0]
        output_path = f"{base_name}_converted.{output_format}"

        cmd = [
            'ffmpeg', '-i', input_path, '-y',
            '-acodec', 'pcm_s16le' if output_format == 'wav' else 'libmp3lame',
            '-ar', '16000',
            '-ac', '1',
            output_path,
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        if result.returncode != 0:
            raise TaskError(f"FFmpeg error: {result.stderr}")

        print(f"Task {task_id}: converted {input_path} → {output_path}")
        return {
            'task_id':      task_id,
            'input_path':   input_path,
            'output_path':  output_path,
            'format':       output_format,
            'callback_url': callback_url,
        }

    except subprocess.TimeoutExpired:
        update_task_status(task_id, "failed", {"error": "Conversion timeout"})
        raise self.retry(exc=TaskError("Conversion timeout"), countdown=10)
    except Exception as e:
        update_task_status(task_id, "failed", {"error": str(e)})
        raise self.retry(exc=e, countdown=10)


@celery_app.task(bind=True, name='denoise')
def denoise(self, task_data: Dict[str, Any]):
    """Применяет шумоподавление (CPU)."""
    task_id      = task_data['task_id']
    input_path   = task_data['output_path']
    callback_url = task_data.get('callback_url', "None")

    update_task_status(task_id, "denoising")
    try:
        base_name   = os.path.splitext(input_path)[0]
        output_path = f"{base_name}_denoised.wav"

        audio, sr = soundfile.read(input_path)
        clean     = noisereduce.reduce_noise(y=audio, sr=sr)
        soundfile.write(output_path, clean, sr)

        os.remove(input_path)   # удаляем временный конвертированный файл
        print(f"Task {task_id}: denoised → {output_path}")

        task_data['denoised_path'] = output_path
        task_data['callback_url']  = callback_url
        return task_data

    except Exception as e:
        update_task_status(task_id, "failed", {"error": str(e)})
        raise self.retry(exc=e, countdown=10)


@celery_app.task(bind=True, name='transcribe')
def transcribe(self, task_data: Dict[str, Any]):
    """
    Отправляет денойзнутый WAV в ASR-сервис (отдельный GPU-контейнер)
    и сохраняет результат.
    """
    task_id      = task_data['task_id']
    input_path   = task_data.get('denoised_path', task_data.get('output_path'))
    callback_url = task_data.get('callback_url', "None")

    update_task_status(task_id, "transcribing")
    try:
        url = f"{ASR_SERVICE_URL}/transcribe"
        with open(input_path, 'rb') as f:
            resp = requests.post(
                url,
                files={"file": (os.path.basename(input_path), f, "audio/wav")},
                data={"task_id": task_id},
                # таймаут большой — длинные файлы обрабатываются долго
                timeout=60 * 30,
            )

        if resp.status_code != 200:
            raise TaskError(f"ASR service error {resp.status_code}: {resp.text}")

        asr_result = resp.json()

        result = {
            'task_id':       task_id,
            'transcription': asr_result.get('full_text', ''),
            'segments':      asr_result.get('segments', []),
            'language':      asr_result.get('language'),
            'processed_files': {
                'original': task_data.get('input_path'),
                'converted': task_data.get('output_path'),
                'denoised':  input_path,
            },
        }

        update_task_status(task_id, "completed", result)
        send_callback(callback_url, task_id, "completed", result)
        print(f"Task {task_id}: transcription completed")
        return result

    except Exception as e:
        error_result = {"error": str(e)}
        update_task_status(task_id, "failed", error_result)
        send_callback(callback_url, task_id, "failed", error_result)
        raise self.retry(exc=e, countdown=10)


@celery_app.task(name='process_audio')
def process_audio(task_id: str, file_path: str, callback_url: str = "None"):
    """Запускает цепочку: convert → denoise → transcribe."""
    update_task_status(task_id, "processing")
    try:
        workflow = chain(
            ffmpeg_convert.s(task_id, file_path, 'wav', callback_url),
            denoise.s(),
            transcribe.s(),
        )
        result = workflow.apply_async()
        return {
            "task_id":  task_id,
            "status":   "processing_started",
            "chain_id": result.id if result else None,
        }
    except Exception as e:
        update_task_status(task_id, "failed", {"error": str(e)})
        send_callback(callback_url, task_id, "failed", {"error": str(e)})
        raise


# ---------------------------------------------------------------------------
# Status helper
# ---------------------------------------------------------------------------

def get_task_status(task_id: str) -> Dict[str, Any]:
    try:
        task_data = redis_client.hgetall(f"task:{task_id}")
        if not task_data:
            return {"status": "not_found"}

        decoded = {
            (k.decode() if isinstance(k, bytes) else k):
            (v.decode() if isinstance(v, bytes) else v)
            for k, v in task_data.items()
        }

        result = {}
        if 'result' in decoded:
            try:
                result = json.loads(decoded['result'])
            except Exception:
                result = {"raw": decoded['result']}

        return {
            "status":     decoded.get('status', 'unknown'),
            "updated_at": float(decoded.get('updated_at', 0)),
            "result":     result,
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}


if __name__ == '__main__':
    print("Starting Celery worker (no GPU)...")
    celery_app.worker_main(argv=['worker', '--loglevel=info', '--concurrency=2'])


